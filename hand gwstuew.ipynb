%%html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hand Gesture Analyzer</title>
    <!-- Load Tailwind CSS for styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Set custom font -->
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        /* Style for video container to overlay canvas */
        .video-container {
            position: relative;
            width: 100%;
            max-width: 640px; /* You can adjust this */
            margin: 0 auto;
            /* 4:3 Aspect Ratio */
            padding-top: 75%; 
        }
        video, canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border-radius: 0.5rem; /* rounded-lg */
        }
        /* Mirror the video feed */
        video {
            transform: scaleX(-1);
        }
        canvas {
            z-index: 10;
        }
    </style>
</head>
<body class="bg-gray-900 text-white min-h-screen flex flex-col items-center justify-center p-4 md:p-8">

    <div class="w-full max-w-3xl text-center space-y-6">
        <h1 class="text-3xl md:text-4xl font-bold">Hand Gesture Analyzer</h1>
        <p class="text-gray-300">Allow webcam access to start gesture detection.</p>

        <!-- Button to Start/Stop Webcam -->
        <button id="webcamButton" class="bg-blue-600 hover:bg-blue-700 text-white font-bold py-3 px-6 rounded-lg text-lg transition-all duration-300 disabled:opacity-50 disabled:cursor-not-allowed">
            Loading Model...
        </button>

        <!-- Video and Canvas Container -->
        <div class="video-container bg-gray-800 rounded-lg shadow-xl overflow-hidden">
            <video id="video" autoplay playsinline></video>
            <canvas id="canvas"></canvas>
        </div>
        
        <!-- Gesture Output -->
        <div class="bg-gray-800 p-4 rounded-lg shadow-inner space-y-2">
            <h2 class="text-2xl font-semibold" id="gesture-output">Gesture: None</h2>
            <h2 class="text-xl font-semibold text-cyan-400" id="measurement-output">Pinch Distance: N/A</h2>
        </div>
    </div>

    <!-- Main Application Logic -->
    <script type="module">
        // Import necessary MediaPipe modules
        import {
            HandLandmarker,
            FilesetResolver
        } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/vision_bundle.js";

        // DOM Elements
        const video = document.getElementById("video");
        const canvasElement = document.getElementById("canvas");
        const canvasCtx = canvasElement.getContext("2d");
        const webcamButton = document.getElementById("webcamButton");
        const gestureOutput = document.getElementById("gesture-output");
        const measurementOutput = document.getElementById("measurement-output");

        // MediaPipe HandLandmarker variables
        let handLandmarker = undefined;
        let runningMode = "VIDEO";
        let webcamRunning = false;
        let lastVideoTime = -1;

        // 1. Function to create and initialize the HandLandmarker
        async function createHandLandmarker() {
            const vision = await FilesetResolver.forVisionTasks(
                "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm"
            );
            handLandmarker = await HandLandmarker.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: `https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task`,
                    delegate: "GPU"
                },
                runningMode: runningMode,
                numHands: 2, // Detect up to 2 hands
                minHandDetectionConfidence: 0.5,
                minHandPresenceConfidence: 0.5,
                minTrackingConfidence: 0.5
            });
            
            // Model loaded, enable the button
            webcamButton.disabled = false;
            webcamButton.textContent = "Start Camera";
        }

        // 2. Event listener for the webcam button
        webcamButton.addEventListener("click", toggleWebcam);

        async function toggleWebcam() {
            if (!handLandmarker) {
                console.log("Wait! HandLandmarker not loaded yet.");
                return;
            }

            webcamRunning = !webcamRunning;

            if (webcamRunning) {
                webcamButton.textContent = "Stop Camera";
                // Get webcam stream
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                    video.srcObject = stream;
                    video.addEventListener("loadeddata", predictWebcam);
                } catch (err) {
                    console.error("Error accessing webcam: ", err);
                    webcamRunning = false; // Reset state
                    webcamButton.textContent = "Start Camera";
                }
            } else {
                webcamButton.textContent = "Start Camera";
                video.removeEventListener("loadeddata", predictWebcam);
                
                // Stop all tracks
                const stream = video.srcObject;
                if (stream) {
                    stream.getTracks().forEach(track => track.stop());
                }
                video.srcObject = null;
                
                // Clear canvas and gesture output
                canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
                gestureOutput.textContent = "Gesture: None";
                measurementOutput.textContent = "Pinch Distance: N/A";
            }
        }

        // 3. The main prediction loop
        async function predictWebcam() {
            // Set canvas size to match video display, only if dimensions are valid
            if (video.videoWidth > 0 && video.videoHeight > 0) {
                canvasElement.width = video.videoWidth;
                canvasElement.height = video.videoHeight;
            }
            
            const now = performance.now();
            if (video.currentTime !== lastVideoTime) {
                lastVideoTime = video.currentTime;

                // Add a check to prevent running detection on a 0-dimension video
                // This fixes the "ROI width and height must be > 0" error
                if (video.videoWidth === 0 || video.videoHeight === 0) {
                    // Continue the loop if webcam is running
                    if (webcamRunning) {
                        window.requestAnimationFrame(predictWebcam);
                    }
                    return; // Skip detection this frame
                }
                
                // Perform hand detection
                handLandmarker.detectForVideo(video, now, (result) => {
                    // Clear the canvas
                    canvasCtx.save();
                    canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
                    
                    // Mirror the canvas to match the mirrored video
                    canvasCtx.scale(-1, 1);
                    canvasCtx.translate(-canvasElement.width, 0);

                    // Process results
                    if (result.landmarks && result.landmarks.length > 0) {
                        // Draw landmarks and connectors
                        for (const landmarks of result.landmarks) {
                            drawLandmarks(canvasCtx, landmarks);
                            drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS);
                        }
                        
                        // Classify gesture (uses 2D landmarks)
                        const gesture = classifyGesture(result.landmarks[0]);
                        gestureOutput.textContent = `Gesture: ${gesture}`;

                        // Calculate measurement (uses 3D world landmarks)
                        if (result.worldLandmarks && result.worldLandmarks.length > 0) {
                            const thumbTip = result.worldLandmarks[0][4]; // Landmark 4
                            const indexTip = result.worldLandmarks[0][8]; // Landmark 8

                            // Calculate 3D distance
                            const distance = getDistance(thumbTip, indexTip);
                            
                            // Convert from meters to centimeters
                            const distanceInCm = distance * 100;
                            
                            measurementOutput.textContent = `Pinch Distance: ${distanceInCm.toFixed(1)} cm`;
                        } else {
                            measurementOutput.textContent = "Pinch Distance: N/A";
                        }

                    } else {
                        // No hands detected
                        gestureOutput.textContent = "Gesture: None";
                        measurementOutput.textContent = "Pinch Distance: N/A";
                    }
                    
                    canvasCtx.restore();
                });
            }

            // Continue the loop if webcam is running
            if (webcamRunning) {
                window.requestAnimationFrame(predictWebcam);
            }
        }

        // 4. Gesture Classification Logic
        function classifyGesture(landmarks) {
            // Get specific landmarks
            // Tip indices: 4 (Thumb), 8 (Index), 12 (Middle), 16 (Ring), 20 (Pinky)
            // MCP joint indices (base knuckle): 5 (Index), 9 (Middle), 13 (Ring), 17 (Pinky)
            // PIP joint indices (middle knuckle): 6 (Index), 10 (Middle), 14 (Ring), 18 (Pinky)
            
            const thumbTip = landmarks[4];
            const indexTip = landmarks[8];
            const middleTip = landmarks[12];
            const ringTip = landmarks[16];
            const pinkyTip = landmarks[20];
            
            const indexMcp = landmarks[5];
            const middleMcp = landmarks[9];
            const ringMcp = landmarks[13];
            const pinkyMcp = landmarks[17];
            
            const indexPip = landmarks[6];
            const middlePip = landmarks[10];
            const ringPip = landmarks[14];
            const pinkyPip = landmarks[18];

            // Simple logic:
            // Check if fingers are extended (tip y-coordinate is less than pip y-coordinate)
            // Note: In browser coordinates, smaller Y is higher up.
            const isIndexExtended = indexTip.y < indexPip.y;
            const isMiddleExtended = middleTip.y < middlePip.y;
            const isRingExtended = ringTip.y < ringPip.y;
            const isPinkyExtended = pinkyTip.y < pinkyPip.y;
            
            // Check for "Open Palm"
            if (isIndexExtended && isMiddleExtended && isRingExtended && isPinkyExtended) {
                return "Open Palm";
            }
            
            // Check for "Closed Fist" (all tips are below their MCP joints)
            const isFist = indexTip.y > indexMcp.y &&
                           middleTip.y > middleMcp.y &&
                           ringTip.y > ringMcp.y &&
                           pinkyTip.y > pinkyMcp.y;
            
            if (isFist) {
                 return "Closed Fist";
            }
            
            // Check for "Pointing" (Index extended, others curled)
            if (isIndexExtended && !isMiddleExtended && !isRingExtended && !isPinkyExtended) {
                return "Pointing";
            }
            
            // Check for "Victory" (Index and Middle extended, others curled)
            if (isIndexExtended && isMiddleExtended && !isRingExtended && !isPinkyExtended) {
                return "Victory";
            }

            return "Other"; // Default case
        }

        // 5. Measurement Logic
        function getDistance(p1, p2) {
            return Math.sqrt(
                Math.pow(p1.x - p2.x, 2) +
                Math.pow(p1.y - p2.y, 2) +
                Math.pow(p1.z - p2.z, 2)
            );
        }

        // 6. Drawing Utilities (Simplified from MediaPipe)
        
        // Landmark drawing function
        function drawLandmarks(ctx, landmarks, options = {}) {
            const { color = '#FF0000', radius = 5 } = options;
            ctx.fillStyle = color;
            for (const point of landmarks) {
                ctx.beginPath();
                ctx.arc(point.x * canvasElement.width, point.y * canvasElement.height, radius, 0, 2 * Math.PI);
                ctx.fill();
            }
        }
        
        // Connector drawing function
        function drawConnectors(ctx, landmarks, connections, options = {}) {
            const { color = '#00FF00', lineWidth = 3 } = options;
            ctx.strokeStyle = color;
            ctx.lineWidth = lineWidth;
            
            for (const connection of connections) {
                const start = landmarks[connection[0]];
                const end = landmarks[connection[1]];
                
                if (start && end) {
                    ctx.beginPath();
                    ctx.moveTo(start.x * canvasElement.width, start.y * canvasElement.height);
                    ctx.lineTo(end.x * canvasElement.width, end.y * canvasElement.height);
                    ctx.stroke();
                }
            }
        }
        
        // Standard HAND_CONNECTIONS from MediaPipe
        const HAND_CONNECTIONS = [
            [0, 1], [1, 2], [2, 3], [3, 4], // Thumb
            [0, 5], [5, 6], [6, 7], [7, 8], // Index
            [5, 9], [9, 10], [10, 11], [11, 12], // Middle
            [9, 13], [13, 14], [14, 15], [15, 16], // Ring
            [13, 17], [0, 17], [17, 18], [18, 19], [19, 20] // Pinky
        ];

        // 7. Start the application
        createHandLandmarker();

    </script>
</body>
</html>
